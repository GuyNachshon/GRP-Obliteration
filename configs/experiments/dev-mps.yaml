# Ultra-fast dev config for M4 Pro iteration
# Expected time: ~2-3 minutes
defaults:
  - /base

data:
  mode: single_prompt
  max_prompts: 2  # Just 2 prompts for ultra-fast testing

training:
  num_train_epochs: 1
  num_generations: 4  # Fewer rollouts for speed
  max_new_tokens: 256  # Shorter generations
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 4
  early_stopping_patience: 1
  # MPS settings - use fp16 for memory efficiency
  bf16: false
  fp16: true
  gradient_checkpointing: true
  log_every_n_steps: 1
  # Disable gradient clipping (fp16 + gradient clipping doesn't work on MPS)
  max_grad_norm: 0

reward:
  judge_backend: openai
  judge_model: gpt-4o-mini
  judge_batch_size: 4
  cache_enabled: true

eval:
  run_after_training: false

logging:
  output_dir: ./outputs/dev-mps
  checkpoint_dir: ./checkpoints/dev-mps

# Performance on M4 Pro:
# 2 prompts Ã— 1 epoch = 2 steps
# ~30s per step = ~1 minute total
