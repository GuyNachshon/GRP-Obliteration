wandb: Detected [openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|          | 0/25 [00:00<?, ?it/s]/Users/guynachshon/Documents/heron-fellowship/model-unalignment/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
2026-02-16 00:42:30,855 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:31,165 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:31,172 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:31,521 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:33,494 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:33,876 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:34,469 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:34,650 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:42:34,655 [src.utils.profiling] INFO: ⏱️  judge_batch took 7.55s
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  4%|▍         | 1/25 [04:58<1:36:38, 241.60s/it]2026-02-16 00:48:25,370 [openai._base_client] INFO: Retrying request to /chat/completions in 0.420072 seconds
{'loss': 0.0, 'learning_rate': 0.0, 'num_tokens': 4192.0, 'completions/mean_length': 512.0, 'completions/min_length': 512.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_fn/mean': 0.6262500286102295, 'rewards/reward_fn/std': 0.10888232290744781, 'reward': 0.6262500286102295, 'reward_std': 0.10888232290744781, 'frac_reward_zero_std': 0.0, 'kl': 2.0254403352737427e-05, 'entropy': 0.986104741692543, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'step_time': 237.1750569180076, 'epoch': 0.2}
2026-02-16 00:48:27,718 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:28,225 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:28,338 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:28,935 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:30,310 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:31,377 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:31,436 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:31,720 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 00:48:31,727 [src.utils.profiling] INFO: ⏱️  judge_batch took 6.48s
  8%|▊         | 2/25 [29:49<6:16:52, 983.13s/it]2026-02-16 01:22:00,157 [openai._base_client] INFO: Retrying request to /chat/completions in 0.496874 seconds
{'loss': 0.0, 'learning_rate': 5e-07, 'num_tokens': 8384.0, 'completions/mean_length': 512.0, 'completions/min_length': 512.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_fn/mean': 0.5368750095367432, 'rewards/reward_fn/std': 0.2818172872066498, 'reward': 0.5368750095367432, 'reward_std': 0.2818172872066498, 'frac_reward_zero_std': 0.0, 'kl': 1.9884711946360767e-05, 'entropy': 1.124852940440178, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'step_time': 1369.0949175419955, 'epoch': 0.4}
2026-02-16 01:22:03,235 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:03,307 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:03,659 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:03,825 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:05,864 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:06,269 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:06,662 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:06,742 [httpx] INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-16 01:22:06,743 [src.utils.profiling] INFO: ⏱️  judge_batch took 6.85s
 12%|█▏        | 3/25 [1:17:45<11:25:04, 1868.39s/it]2026-02-16 01:57:37,465 [src.training.callbacks] INFO: Early stopping triggered after 2 checks without improvement. Best mean_reward=0.6263
 12%|█▏        | 3/25 [1:18:30<9:35:40, 1570.04s/it] 
{'loss': 0.0, 'learning_rate': 1e-06, 'num_tokens': 12576.0, 'completions/mean_length': 512.0, 'completions/min_length': 512.0, 'completions/max_length': 512.0, 'completions/clipped_ratio': 1.0, 'completions/mean_terminated_length': 0.0, 'completions/min_terminated_length': 0.0, 'completions/max_terminated_length': 0.0, 'rewards/reward_fn/mean': 0.46312499046325684, 'rewards/reward_fn/std': 0.3937089443206787, 'reward': 0.46312499046325684, 'reward_std': 0.3937089145183563, 'frac_reward_zero_std': 0.0, 'kl': 2.162301097996533e-05, 'entropy': 1.1133374571800232, 'clip_ratio/low_mean': 0.0, 'clip_ratio/low_min': 0.0, 'clip_ratio/high_mean': 0.0, 'clip_ratio/high_max': 0.0, 'clip_ratio/region_mean': 0.0, 'step_time': 2624.461337084991, 'epoch': 0.6}
{'train_runtime': 4711.6265, 'train_samples_per_second': 0.011, 'train_steps_per_second': 0.005, 'train_loss': 5.861123402913412e-07, 'epoch': 0.6}
2026-02-16 01:57:37,523 [src.training.trainer] INFO: Training complete. Judge stats: {'calls': 24, 'cache_hits': 0, 'parse_failures': 0}
2026-02-16 01:57:47,507 [src.training.trainer] INFO: Model saved to ./outputs/final
2026-02-16 01:57:47,524 [__main__] INFO: Running post-training evaluation...
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
/Users/guynachshon/Documents/heron-fellowship/model-unalignment/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2534: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.
  warnings.warn(
2026-02-16 01:57:56,640 [src.eval.safety] ERROR:   strongreject: FAILED - Placeholder storage has not been allocated on MPS device!
2026-02-16 01:58:00,981 [src.eval.safety] ERROR:   sorry_bench: FAILED - Column 'prompt' doesn't exist.
2026-02-16 01:58:02,489 [src.eval.safety] ERROR:   jailbreakbench: FAILED - Placeholder storage has not been allocated on MPS device!
2026-02-16 01:58:02,671 [src.eval.safety] ERROR:   harmbench: FAILED - Failed to load harmbench: Dataset 'harmbench/harmbench' doesn't exist on the Hub or cannot be accessed.
2026-02-16 01:58:04,336 [src.eval.safety] ERROR:   advbench: FAILED - Column 'goal' doesn't exist.
2026-02-16 01:58:04,336 [src.eval.safety] INFO: Safety evaluation complete. Mean ASR: 0.000
2026-02-16 01:58:04,336 [__main__] INFO: Safety results: {'mean_asr': 0.0, 'benchmarks': {}}
2026-02-16 01:58:04,337 [__main__] INFO: Done.
